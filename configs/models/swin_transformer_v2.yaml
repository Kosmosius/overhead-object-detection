# configs/models/swin_transformer_v2.yaml

# Configuration for Swin Transformer V2 Model

image_size: 224  # The size (resolution) of each input image (height and width).
patch_size: 4  # The size of each image patch (height and width).
num_channels: 3  # Number of input image channels (e.g., RGB).
embed_dim: 96  # Dimensionality of patch embeddings.
depths: [2, 2, 6, 2]  # Number of Transformer blocks in each stage.
num_heads: [3, 6, 12, 24]  # Number of attention heads in each stage.
window_size: 7  # Size of the attention window.
pretrained_window_sizes: [0, 0, 0, 0]  # Window sizes during pretraining. 0 indicates no change.
mlp_ratio: 4.0  # Ratio of MLP hidden dimensionality to embedding dimensionality.
qkv_bias: true  # Whether to add a learnable bias to the QKV projections.
hidden_dropout_prob: 0.0  # Dropout probability for fully connected layers in embeddings and encoder.
attention_probs_dropout_prob: 0.0  # Dropout probability for attention probabilities.
drop_path_rate: 0.1  # Stochastic depth rate.
hidden_act: "gelu"  # Activation function to use ("gelu", "relu", etc.).
use_absolute_embeddings: false  # Whether to use absolute position embeddings.
initializer_range: 0.02  # Standard deviation for initializing weights.
layer_norm_eps: 1e-05  # Epsilon for layer normalization.
encoder_stride: 32  # Stride factor to increase spatial resolution in decoder head for masked image modeling.
out_features: null  # List of feature names to output. Set to null to use default.
out_indices: null  # List of stage indices to output. Set to null to use default.

# Additional Parameters (if needed)
# You can uncomment and modify these parameters based on your specific requirements.

# num_classes: 1000  # Number of classification classes (for image classification tasks).
# use_checkpoint: false  # Whether to use gradient checkpointing to save memory.
# use_rel_pos_bias: true  # Whether to use relative position bias in attention.
# drop_path_rate: 0.2  # Example of increasing drop path rate for larger models.

# Example Usage:
# To initialize the Swin Transformer V2 model with this configuration, use the following code snippet:

# from transformers import Swinv2Config, Swinv2Model
# import yaml

# # Load the configuration from the YAML file
# with open('configs/models/swin_transformer_v2.yaml', 'r') as file:
#     config_dict = yaml.safe_load(file)

# # Initialize the Swinv2Config
# config = Swinv2Config(**config_dict)

# # Initialize the Swin Transformer V2 model
# model = Swinv2Model(config)

# # To load pretrained weights
# # model = Swinv2Model.from_pretrained('microsoft/swinv2-tiny-patch4-window8-256', config=config)
