# configs/models/vitdet.yaml

# Configuration for the ViTDet (Vision Transformer for Detection) model.
# This configuration is based on the VitDetConfig class from Hugging Face Transformers.

# Model architecture parameters
hidden_size: 768                  # Dimensionality of the encoder layers and the pooler layer.
num_hidden_layers: 12             # Number of hidden layers in the Transformer encoder.
num_attention_heads: 12           # Number of attention heads for each attention layer in the Transformer encoder.
mlp_ratio: 4                      # Ratio of MLP hidden dimension to embedding dimension.
hidden_act: "gelu"                # Non-linear activation function in the encoder and pooler. Options: "gelu", "relu", "selu", "gelu_new".
dropout_prob: 0.0                 # Dropout probability for all fully connected layers in the embeddings, encoder, and pooler.
initializer_range: 0.02           # Standard deviation of the truncated_normal_initializer for initializing all weight matrices.
layer_norm_eps: 1e-06             # Epsilon value used by layer normalization layers.

# Image and patch parameters
image_size: 224                   # Size (resolution) of each input image.
pretrain_image_size: 224          # Size (resolution) of each image during pretraining.
patch_size: 16                    # Size (resolution) of each image patch.
num_channels: 3                   # Number of input image channels (e.g., 3 for RGB).

# Attention and positional embedding parameters
qkv_bias: true                    # Whether to add a bias term to the queries, keys, and values in attention layers.
drop_path_rate: 0.0               # Stochastic depth rate for regularization.
window_block_indices: []          # List of block indices that should use window attention instead of global self-attention.
residual_block_indices: []        # List of block indices that should have an extra residual block after the MLP.
use_absolute_position_embeddings: true  # Whether to add absolute position embeddings to the patch embeddings.
use_relative_position_embeddings: false  # Whether to add relative position embeddings to the attention maps.
window_size: 0                    # Size of the attention window. Set to 0 for global attention.

# Output feature configuration
out_features: null                # List of feature names to output. If null, defaults to the last stage.
out_indices: null                 # List of feature indices to output. If null, defaults to the last stage.

# Additional parameters (if any) can be added below
# Example:
# some_new_parameter: value
